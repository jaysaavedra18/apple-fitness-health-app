{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Health Metrics - Data Cleaning\n",
    "## Table of Contents\n",
    "1. [Setup Packages and Config](#setup-packages-and-config)\n",
    "2. [Import Data](#import-data)\n",
    "3. [Clean the Data](#clean-the-data)\n",
    "   - [Flatten Nested Columns](#flatten-nested-columns)\n",
    "   - [Convert Dates to DateTime](#convert-dates-to-datetime)\n",
    "4. [Validate and Save Cleaned Data](#validate-and-save-cleaned-data)\n",
    "5. [Preparing for Data Analysis](#data-analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Packages and Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data\n",
    "data = pd.read_json('../original_data/data.json')[\"data\"]\n",
    "\n",
    "# Extract 'workouts' and 'metrics' DataFrames\n",
    "wdf = pd.DataFrame(data[\"workouts\"])\n",
    "\n",
    "metrics_list = []\n",
    "for metric in data[\"metrics\"]:\n",
    "    df = pd.DataFrame(metric['data'])\n",
    "    df['metric'] = metric['name']\n",
    "    df['units'] = metric['units']\n",
    "    metrics_list.append(df)\n",
    "\n",
    "# Combine all metrics into a single DataFrame\n",
    "mdf = pd.concat(metrics_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clean the Data\n",
    "## 3.1 Flatten Nested Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the nested columns in the 'workouts' DataFrame\n",
    "def extract_qty_column(df, column_name):\n",
    "    if column_name in df.columns:\n",
    "        df[f'{column_name}_qty'] = df[column_name].apply(lambda x: x['qty'] if isinstance(x, dict) else x)\n",
    "    else:\n",
    "        df[f'{column_name}_qty'] = np.nan\n",
    "    return df\n",
    "\n",
    "# Extract the qty from all relevant columns\n",
    "columns_to_extract = ['activeEnergyBurned', 'distance', 'lapLength', 'intensity', 'humidity', 'temperature']\n",
    "for column_name in columns_to_extract:\n",
    "    wdf = extract_qty_column(wdf, column_name)\n",
    "\n",
    "# Drop the original columns\n",
    "wdf.drop(columns=columns_to_extract, axis=1, inplace=True)\n",
    "\n",
    "# Rename 'qty' for clarity\n",
    "mdf.rename(columns={'qty': 'value'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Convert Dates to DateTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Dates to DateTime objects\n",
    "wdf['start'] = pd.to_datetime(wdf['start'], format='%Y-%m-%d %H:%M:%S %z')\n",
    "wdf['end'] = pd.to_datetime(wdf['end'], format='%Y-%m-%d %H:%M:%S %z')\n",
    "mdf['date'] = pd.to_datetime(mdf['date'], format='%Y-%m-%d %H:%M:%S %z')\n",
    "# Count the number of missing values in each column \n",
    "print(wdf.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validate and Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate cleaned data\n",
    "print(wdf.head()) \n",
    "# Save the cleaned data\n",
    "wdf.to_csv('../cleaned_data/cl_workouts.csv', index=False)\n",
    "mdf.to_csv('../cleaned_data/cl_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Analysis\n",
    "#### Find important statistics including count, mean, and standard deviation of each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by metric for visualization/analysis\n",
    "grouped = mdf.groupby('metric')\n",
    "print(grouped['value'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find and display the correlation matrix. This shows the correlation between any health metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot data for correlation analysis\n",
    "pivoted_df = mdf.pivot(index='date', columns='metric', values='value')\n",
    "# Calculate correlations\n",
    "correlation_matrix = pivoted_df.corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find linear regression to help understand and predict the relationship between a dependent var (target) and one or more independent vars (predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import linear_regression\n",
    "linear_regression(pivoted_df, 'apple_exercise_time', 'swimming_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import plot_trends\n",
    "\n",
    "# Plot trends for each metric\n",
    "for metric, group in df.groupby('metric'):\n",
    "    plot_trends(group, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
